import streamlit as st
import time
from prompt import firePrompt

st.set_page_config(page_title='Local LLM',
                   page_icon='ğŸ’ğŸ»â€â™‚ï¸',
                   layout='wide',
                   initial_sidebar_state='expanded'
                )

if 'messages' not in st.session_state:
    st.session_state.messages = []

if 'temp' not in st.session_state:
    st.session_state.temp = 0

with st.sidebar:
    st.markdown('## à®à®©à®¤à¯ à®•à®±à¯à®ªà®©à¯ˆ à®¤à®¿à®±à®©à¯ˆ à®¤à¯‡à®°à¯à®µà¯ à®šà¯†à®¯à¯à®• !', unsafe_allow_html=True)
    st.session_state.temp = st.slider(label='temp', min_value=0.0, 
                                      max_value=1.0, step=0.1, value=0.3, label_visibility='hidden')
    st.image('sidebar_logo.png', use_column_width=True)
    st.image('RVSR.png', use_column_width=True)

def getAvatar(role):
    if role == 'assistant':
        return "tamil-llama-logo2.png"
    else :
        return "RVSR.png"

def getContext():
    res = ""
    for item in st.session_state.messages[:-1]:
        res = res + f"role : {item['role']} content : {item['content']}\n"
    return res

st.markdown('# :red[Local] ğŸ  :yellow[Private] ğŸ”’ :neon[à®¤à®®à®¿à®´à¯ AI Assistant] ğŸ¤–', unsafe_allow_html=True)
st.markdown('## :rainbow[Powered by à®¤à®®à®¿à®´à¯ ğŸ¦™ğŸ¦™ğŸ¦™ & VIDYASAGR ] ', unsafe_allow_html=True)

with st.chat_message(name="assistant", avatar='tamil-llama-logo2.png'):
    st.markdown('#### Ask me anything! à®à®©à¯à®©à®¿à®Ÿà®®à¯ à®¤à®®à®¿à®´à®¿à®²à¯à®®à¯ à®‰à®°à¯ˆà®¯à®¾à®Ÿà®²à®¾à®®à¯! ğŸ™ğŸ»')
for message in st.session_state.messages:
    with st.chat_message(name=message["role"], avatar=getAvatar(message["role"])):
        st.markdown(f'{message["content"]}')

if prompt := st.chat_input(placeholder="Chat with me. à®à®©à¯à®©à®¿à®Ÿà®®à¯ à®¤à®®à®¿à®´à®¿à®²à¯à®®à¯ à®‰à®°à¯ˆà®¯à®¾à®Ÿà®²à®¾à®®à¯!"):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message(name="user", avatar='RVSR.png'):
        st.markdown(prompt)
    with st.chat_message(name='assistant', avatar='tamil-llama-logo2.png'):
        message_placeholder = st.empty()
        full_response = ""
        with st.spinner(text="Thinking... ğŸ’­ğŸ’­ğŸ’­"):
            raw = firePrompt(st.session_state.messages[-1]['content'], temp=st.session_state.temp)
            response = str(raw)
            # Simulate stream of response with milliseconds delay
            for chunk in response.split():
                full_response += chunk + " "
                time.sleep(0.05)
                # Add a blinking cursor to simulate typing
                message_placeholder.markdown(full_response + "â–Œ", unsafe_allow_html=True)
            message_placeholder.markdown(f'#### {full_response}', unsafe_allow_html=True)
            st.session_state.messages.append({"role": "assistant", "content": full_response})